# 최근에는 사용자 트래픽이 증가할 때 부하 처리 관련해서 공부하고 있습니다. 예를 들어 제가 만든 프로젝트에서 사용자 트래픽이 증가했을 때 고가용성을 유지하면서 어떻게 부하처리를 해야할지 공부하고 있습니다. 위 상황에서는 제가 생각하기에는 그냥 사용자가 증가할 경우 먼저 저희 서비스는 단일 서버 구조이기 때문에 이중화를 통해 가용성을 유지할 수 있을 것 같습니다. 서버를 두 개 혹은 그 이상으로 스케일 아웃 하여 한 서버거 다운되더라도 다른 서버로 트래픽을 처리할 수 있을 것 같습니다. 그리고 스케일 아웃을 하면 앞 단에 있는 리버스 프록시 Nginx를 통해 트래픽을 분산하여 처리하여 해결할 수 있을 것 같습니다. 하지만 DB를 많이 거칠 경우 저희는 DB도 단일 서버 구조이기 때문에 DB서버도 다운이 생기면 바로 서비스 사용에 문제가 되기 때문에 DB 서버 구조도 변경할 필요가 있습니다. 이는 대부분 서비스가 SELECT 쿼리문이  80%이상을 이루고 있기 때문에 replication을 통해 해결할 수 있을 것 같습니다. 비슷한 기술로는 클러스터링도있지만 클러스터링은 DB 트래픽은 분산할 수 있어도 DB 스토리지는 결국 1개이기 때문에  레플리케이션 방식이 더 효율적이라고 생각했습니다. 레플리케이션을 통해 Master-Slave구조로 slave 쪽에 select 문을 처리하고, 만약 Master 서버에 문제가 생겨도 failover를 통해 해결할 수 있을 것 입니다. 하지만 failover 시에 복제지연이 문제가 될 수 있지만 이는 데이터 일관성이 많이 중요한 서비스의 경우 동기식 방식으로 변경하여 해결할 수 도 있고, 반동기 방식을 통해 바이너리 로그파일 전송 응답을 받는 방식으로 바꾸어 해결할 수도 있을 것 같습니다. 
# 사용자가 전반적으로 증가할 경우 위와같이 할 수 있겠지만, 만약 티케팅 사이트와 같이 갑자기 트래픽이 몰리는 경우에는 조금 다릅니다. 이는 스케일 업 혹은 스케일 아웃을 통한 로드밸런싱은 미비한 효과와 너무 큰 비용을 요구하기 때문에 적절하지 않을 수 있습니다. 제가 생각할 때는 네트워크 속도가 CPU처리속도보다 훨씬 느리기 때문에 보통 티케팅 사이트에서 병목현상이 생기는데 이는 먼저 요청이 들어오면 바로 처리하지말고, 변수나 json 에 저장을 먼저 해놓고 사용자들에게는 대기열 시스템을 통해 기다릴 수 있도록 처리하고, batch를 통해 만 건씩 통째로 저장했던 요청들을 따로 처리할 수 있으면 완화할 수 있지 않을까 생각합니다.
#
# 아직 미흡하고 공부하고 있지만 정말 다양한 방식이 있는 것 같습니다. 서비스의 형태와 어떤 걸 중요시 하는지 예를 들면 속도를 중요시 하는지 아니면 데이터의 일관성을 더 중요시 하는지 등 다양한 관점에서 모두 정답이 다른 것 같아 재밌고 어려운 것 같습니다.